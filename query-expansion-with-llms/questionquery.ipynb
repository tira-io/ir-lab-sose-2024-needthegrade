{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import openai\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI() #connect to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(prompt, model=\"gpt-4\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = pt_dataset.get_topics('query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>52</td>\n",
       "      <td>reverse indexing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>53</td>\n",
       "      <td>index compression techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>54</td>\n",
       "      <td>search engine optimization with query logs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>55</td>\n",
       "      <td>bm25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>56</td>\n",
       "      <td>what makes natural language processing natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>57</td>\n",
       "      <td>principle of a information retrieval indexing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>58</td>\n",
       "      <td>architecture of web search engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>59</td>\n",
       "      <td>what is ahp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>60</td>\n",
       "      <td>what is information retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>61</td>\n",
       "      <td>efficient retrieval algorithms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                           query\n",
       "50  52                                reverse indexing\n",
       "51  53                    index compression techniques\n",
       "52  54      search engine optimization with query logs\n",
       "53  55                                            bm25\n",
       "54  56  what makes natural language processing natural\n",
       "55  57   principle of a information retrieval indexing\n",
       "56  58               architecture of web search engine\n",
       "57  59                                     what is ahp\n",
       "58  60                   what is information retrieval\n",
       "59  61                  efficient retrieval algorithms"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querys[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': False, '2': False, '3': False, '4': False, '5': False, '6': False, '7': False, '8': False, '9': False, '10': False, '11': False, '12': False, '13': False, '14': False, '15': False, '16': False, '17': False, '19': False, '20': False, '21': False, '22': False, '23': False, '24': False, '25': False, '26': False, '27': False, '28': False, '29': False, '30': False, '31': False, '32': False, '33': False, '34': False, '35': False, '36': False, '37': False, '38': False, '39': False, '40': False, '41': False, '42': False, '43': False, '44': False, '45': False, '46': False, '47': False, '48': False, '49': False, '50': False, '51': False, '52': False, '53': False, '54': False, '55': False, '56': True, '57': False, '58': False, '59': True, '60': True, '61': False, '62': False, '63': False, '64': False, '65': False, '66': False, '67': False, '68': False, '18': False}\n"
     ]
    }
   ],
   "source": [
    "answers = dict()\n",
    "for i in range(len(querys)):\n",
    "    determine_abbrevation = f\"\"\" \n",
    "    You are an scientific expert especially in the domain of Information Retrieval. Your task is to detect whether\n",
    "    a given query, which is given as a text below delimited by triple quotes, is a question. You can detect whether a query\n",
    "    is a question if it contains question words like 'What' or 'Why'.\n",
    "    For example given a query 'What is crx' you should answer yes, since the query contains 'What' which is a \n",
    "    question word. However if the given query is 'Information Retrieval' you should answer no, since there is no\n",
    "    question word in the query.\n",
    "\n",
    "    query: '''{querys['query'][i]}'''\n",
    "    \"\"\"\n",
    "    answer = ask_gpt(prompt=determine_abbrevation) #check answer more carefully perhaps model will return not only {yes,no}\n",
    "    #print(answer)\n",
    "    qid = str(querys['qid'][i])\n",
    "    if \"yes\" in answer.lower().strip():\n",
    "        answers[qid] = True\n",
    "    else:\n",
    "        answers[qid] = False\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old query:  what makes natural language processing natural\n",
      "New query:   fundamentals of natural language processing \n",
      " understanding natural language processing \n",
      " concepts behind natural language processing \n",
      " principles of natural language processing \n",
      " nature of natural language processing \n",
      "Old query:  what is ahp\n",
      "New query:   introduction to ahp \n",
      " overview of ahp \n",
      " basic concepts of ahp \n",
      " understanding ahp \n",
      " principles of ahp \n",
      " fundamentals of ahp \n",
      "Old query:  what is information retrieval\n",
      "New query:   introduction to information retrieval \n",
      " overview of information retrieval \n",
      " basic concepts of information retrieval \n",
      " principles of information retrieval \n",
      " understanding information retrieval \n",
      " fundamentals of information retrieval \n"
     ]
    }
   ],
   "source": [
    "for key in answers.keys():\n",
    "    if bool(answers[key]):\n",
    "        #find query\n",
    "        for i in range(len(querys)):\n",
    "            if querys['qid'][i] == key:\n",
    "                query= querys['query'][i]\n",
    "                print(\"Old query: \",query)\n",
    "        #ask gpt to expand query\n",
    "        expand = f\"\"\" \n",
    "        You are an expert in Information Retrieval.  I am building an retrieval System specificially for the scientific domain, just like Google Scholar I want to find scientific papers for a query,. I want to improve the precision of my retrieval system by expanding specific question querys. Please understand that the information need behind a question query is much different than for a keyword query. For example the intent behind a question query like \"What is Deep Learning\" much more likely is to find papers that focus on an introduction to deep learning and explains core concepts. Meanwhile the intent behind the keyword query \"Deep Learning\" is find any papers that focus on deep learning.\n",
    "        Your task is to semanticly interpret a question query, which is below delimited by triple quotes, and return three to six expanded queries so I can gather the score for each query and then aggregate over the scores to calculate a final score. Here are some examples:\n",
    "        For the question query 'What is deep learning' the intent is to find papers that introduce and explain deep learning. Therefore expanded querys could be:\n",
    "        'Introduction to deep Learning'\n",
    "        'Overview of deep Learning'\n",
    "        'basic concepts of deep learning'\n",
    "        For the question query 'Why use boolean retrieval model' the inent is to find papers that gve insights to reasons to apply the boolean retrieval model. Therefore expanded querys could be:\n",
    "        'Reasons to use boolean retrieval model'\n",
    "        'Introduction to boolean retrieval model'\n",
    "\n",
    "        query: '''{query}'''\n",
    "        \"\"\"\n",
    "        new_query = ask_gpt(prompt=expand).lower().strip().replace(\"'\", \" \").replace('\"', ' ')\n",
    "        print(\"New query: \",new_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
