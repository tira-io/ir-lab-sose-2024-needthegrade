{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify which querys are question querys\n",
    "#delete them from the list but keep information\n",
    "#rank the querys with bm25\n",
    "#rank the question queries seperately:\n",
    "    #gpt generates sub querys\n",
    "    #bm25.search() for each sub query\n",
    "    #aggregate score\n",
    "    #update original query score\n",
    "\n",
    "#always keep track of information qid, docid, docno etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import openai\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI() #connect to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(prompt, model=\"gpt-4\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = pt_dataset.get_topics('query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': False, '2': False, '3': False, '4': False, '5': False, '6': False, '7': False, '8': False, '9': False, '10': False, '11': False, '12': False, '13': False, '14': False, '15': False, '16': False, '17': False, '19': False, '20': False, '21': False, '22': False, '23': False, '24': False, '25': False, '26': False, '27': False, '28': False, '29': False, '30': False, '31': False, '32': False, '33': False, '34': False, '35': False, '36': False, '37': False, '38': False, '39': False, '40': False, '41': False, '42': False, '43': False, '44': False, '45': False, '46': False, '47': False, '48': False, '49': False, '50': False, '51': False, '52': False, '53': False, '54': False, '55': False, '56': True, '57': False, '58': False, '59': True, '60': True, '61': False, '62': True, '63': False, '64': False, '65': False, '66': False, '67': False, '68': False, '18': False}\n"
     ]
    }
   ],
   "source": [
    "answers = dict()\n",
    "for i in range(len(querys)):\n",
    "    determine_abbrevation = f\"\"\" \n",
    "    You are an scientific expert especially in the domain of Information Retrieval. Your task is to detect whether\n",
    "    a given query, which is given as a text below delimited by triple quotes, is a question. You can detect whether a query\n",
    "    is a question if it contains question words like 'What' or 'Why'.\n",
    "    For example given a query 'What is crx' you should answer yes, since the query contains 'What' which is a \n",
    "    question word. However if the given query is 'Information Retrieval' you should answer no, since there is no\n",
    "    question word in the query.\n",
    "\n",
    "    query: '''{querys['query'][i]}'''\n",
    "    \"\"\"\n",
    "    answer = ask_gpt(prompt=determine_abbrevation) #check answer more carefully perhaps model will return not only {yes,no}\n",
    "    #print(answer)\n",
    "    qid = str(querys['qid'][i])\n",
    "    if \"yes\" in answer.lower().strip():\n",
    "        answers[qid] = True\n",
    "    else:\n",
    "        answers[qid] = False\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old query:  what makes natural language processing natural\n",
      "New query:   understanding natural language processing$ \n",
      " principles of natural language processing$ \n",
      " introduction to natural language processing$ \n",
      " fundamentals of natural language processing$ \n",
      " concepts behind natural language processing$ \n",
      "Old query:  what is ahp\n",
      "New query:   introduction to ahp$ \n",
      " overview of ahp$ \n",
      " basic concepts of ahp$ \n",
      " understanding ahp$ \n",
      " principles of ahp$ \n",
      "Old query:  what is information retrieval\n",
      "New query:   introduction to information retrieval$ \n",
      " overview of information retrieval$ \n",
      " basic concepts of information retrieval$ \n",
      " principles of information retrieval$ \n",
      " understanding information retrieval$ \n",
      "Old query:  how to avoid spam results\n",
      "New query:   preventing spam results$ \n",
      " methods to filter spam results$ \n",
      " guide to avoid spam in search results$ \n",
      " strategies to eliminate spam results$ \n",
      " understanding spam results and how to avoid them$ \n"
     ]
    }
   ],
   "source": [
    "questions = list()\n",
    "for key in answers.keys():\n",
    "    if bool(answers[key]):\n",
    "        #find query\n",
    "        for i in range(len(querys)):\n",
    "            if querys['qid'][i] == key:\n",
    "                query= querys['query'][i]\n",
    "                print(\"Old query: \",query)\n",
    "        #ask gpt to expand query\n",
    "        expand = f\"\"\" \n",
    "        You are an expert in Information Retrieval.  I am building an retrieval System specificially for the scientific domain, just like Google Scholar I want to find scientific papers for a query,. I want to improve the precision of my retrieval system by expanding specific question querys. Please understand that the information need behind a question query is much different than for a keyword query. For example the intent behind a question query like \"What is Deep Learning\" much more likely is to find papers that focus on an introduction to deep learning and explains core concepts. Meanwhile the intent behind the keyword query \"Deep Learning\" is find any papers that focus on deep learning.\n",
    "        Your task is to semanticly interpret a question query, which is below delimited by triple quotes, and return three to six expanded queries so I can gather the score for each query and then aggregate over the scores to calculate a final score. Here are some examples:\n",
    "        For the question query 'What is deep learning' the intent is to find papers that introduce and explain deep learning. At the end of each query please add a '$'.\n",
    "        Therefore expanded querys could be:\n",
    "        'Introduction to deep Learning$'\n",
    "        'Overview of deep Learning$'\n",
    "        'basic concepts of deep learning$'\n",
    "        For the question query 'Why use boolean retrieval model' the inent is to find papers that gve insights to reasons to apply the boolean retrieval model. Therefore expanded querys could be:\n",
    "        'Reasons to use boolean retrieval model$'\n",
    "        'Introduction to boolean retrieval model$'\n",
    "\n",
    "        query: '''{query}'''\n",
    "        \"\"\"\n",
    "        new_query = ask_gpt(prompt=expand).lower().strip().replace(\"'\", \" \").replace('\"', ' ')\n",
    "        print(\"New query: \",new_query)\n",
    "        questions.append({query: new_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'what makes natural language processing natural': ' understanding natural language processing$ \\n principles of natural language processing$ \\n introduction to natural language processing$ \\n fundamentals of natural language processing$ \\n concepts behind natural language processing$ '}, {'what is ahp': ' introduction to ahp$ \\n overview of ahp$ \\n basic concepts of ahp$ \\n understanding ahp$ \\n principles of ahp$ '}, {'what is information retrieval': ' introduction to information retrieval$ \\n overview of information retrieval$ \\n basic concepts of information retrieval$ \\n principles of information retrieval$ \\n understanding information retrieval$ '}, {'how to avoid spam results': ' preventing spam results$ \\n methods to filter spam results$ \\n guide to avoid spam in search results$ \\n strategies to eliminate spam results$ \\n understanding spam results and how to avoid them$ '}]\n"
     ]
    }
   ],
   "source": [
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['understanding natural language processing', '   principles of natural language processing', '   introduction to natural language processing', '   fundamentals of natural language processing', '   concepts behind natural language processing', ''], ['introduction to ahp', '   overview of ahp', '   basic concepts of ahp', '   understanding ahp', '   principles of ahp', ''], ['introduction to information retrieval', '   overview of information retrieval', '   basic concepts of information retrieval', '   principles of information retrieval', '   understanding information retrieval', ''], ['preventing spam results', '   methods to filter spam results', '   guide to avoid spam in search results', '   strategies to eliminate spam results', '   understanding spam results and how to avoid them', '']]\n"
     ]
    }
   ],
   "source": [
    "split_q = list()\n",
    "for query in questions:\n",
    "    for key in query:\n",
    "        query = query[key].replace('\\n', ' ').strip()\n",
    "        split_q.append(query.split('$'))\n",
    "print(split_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now do the ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_queries = split_q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def score_documents(subqueries, retriever, qid, original_query):\n",
    "    final_scores = {}\n",
    "\n",
    "    for subquery in subqueries:\n",
    "        results = retriever.search(subquery)\n",
    "        for index, row in results.iterrows():\n",
    "            doc_id = row['docno']\n",
    "            score = row['score']\n",
    "            docno = row['docno']\n",
    "            \n",
    "            if doc_id in final_scores:\n",
    "                final_scores[doc_id]['score'] += score\n",
    "            else:\n",
    "                final_scores[doc_id] = {'score': score, 'docno': docno}\n",
    "\n",
    "    # Convert the final scores to a list of dictionaries\n",
    "    results_list = [\n",
    "        {'qid': qid, 'docid': doc_id, 'docno': details['docno'], 'score': details['score'], 'query': original_query}\n",
    "        for doc_id, details in final_scores.items()\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame from the results list\n",
    "    results_df = pd.DataFrame(results_list).sort_values(by='score', ascending=False)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyterrier/batchretrieve.py:307: UserWarning: Skipping empty query for qid 1\n",
      "  warn(\"Skipping empty query for qid %s\" % qid)\n"
     ]
    }
   ],
   "source": [
    "run = score_documents(sub_queries, bm25, 1, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     qid     docid     docno      score query\n",
      "14     1  J86-2001  J86-2001  73.413873  test\n",
      "302    1  J95-3006  J95-3006  69.230891  test\n",
      "484    1  N03-5001  N03-5001  69.113129  test\n"
     ]
    }
   ],
   "source": [
    "print(run.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "run.loc[1] = [1,'abc','321', 73.0, 'test']\n",
    "print(run.at[1, 'docid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  qid   docid                               docno  rank      score  \\\n",
      "1   1  125137   1989.ipm_journal-ir0volumeA25A4.2     1   0.000000   \n",
      "2   1  125817  2005.ipm_journal-ir0volumeA41A5.11     2  14.144223   \n",
      "\n",
      "                                      query  \n",
      "1  retrieval system improving effectiveness  \n",
      "2  retrieval system improving effectiveness  \n"
     ]
    }
   ],
   "source": [
    "run.at[1, 'score'] = 0\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through querys and determine which is a question query\n",
    "#perform normal bm25 ranking for each query except question querys\n",
    "#rank question querys seperately:\n",
    "    #generate sub querys with gpt\n",
    "    #score each sub query with bm25.search()\n",
    "    #aggregate scores of each sub query to final score for original query\n",
    "#add ranking rows to bm25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGHT 4\n",
      "  qid         docid                               docno rank      score  \\\n",
      "0   1         94858        2004.cikm_conference-2004.47    0  15.681777   \n",
      "1   1        125137   1989.ipm_journal-ir0volumeA25A4.2    1  15.047380   \n",
      "2   1        125817  2005.ipm_journal-ir0volumeA41A5.11    2  14.144223   \n",
      "4   1  918366899762                                 abc    a  17.000000   \n",
      "\n",
      "                                      query  \n",
      "0  retrieval system improving effectiveness  \n",
      "1  retrieval system improving effectiveness  \n",
      "2  retrieval system improving effectiveness  \n",
      "4                                      test  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20054/2019941890.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  run3.loc[4]= [1,918366899762, 'abc', 'a', 17, 'test']\n"
     ]
    }
   ],
   "source": [
    "run2 = bm25(querys)\n",
    "run3 = run2[:3]\n",
    "\n",
    "\n",
    "run3.loc[4]= [1,918366899762, 'abc', 'a', 17, 'test']\n",
    "print(\"LENGHT\",len(run3))\n",
    "print(run3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
