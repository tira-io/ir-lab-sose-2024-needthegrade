{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take llm's to interpret abbrevations and expand the query accordingly for better result\n",
    "#advanced: detect if term is medical and then instead of llm's use a dictionary as it is more precise\n",
    "#optionals:\n",
    "    #detect if query is a question query and prompt LLM to answer question, then expand query with keywords\n",
    "    #get query and analyze most important part through LLM, then append that part multiple times to query     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM's interprete abbrevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import openai\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI() #connect to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(prompt, model=\"gpt-4\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alter query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through each query in pt_dataset.get_topics('query')\n",
    "#for query decide whether this query contains an abbrevation or not\n",
    "#if query contains abbrevation expand the query through writing out the abbrevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>machine learning language identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>social media detect self harm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                                     query\n",
       "0   1  retrieval system improving effectiveness\n",
       "1   2  machine learning language identification\n",
       "2   3             social media detect self harm"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querys = pt_dataset.get_topics('query')\n",
    "querys.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval system improving effectiveness\n"
     ]
    }
   ],
   "source": [
    "print(querys['query'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine if query contains abbrevation using gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': False, '2': False, '3': False, '4': False, '5': False, '6': False, '7': False, '8': False, '9': False, '10': False, '11': True, '12': False, '13': False, '14': False, '15': False, '16': False, '17': False, '19': False, '20': False, '21': False, '22': False, '23': False, '24': False, '25': False, '26': False, '27': False, '28': False, '29': False, '30': False, '31': False, '32': False, '33': False, '34': False, '35': False, '36': False, '37': False, '38': False, '39': False, '40': False, '41': False, '42': False, '43': False, '44': False, '45': False, '46': False, '47': False, '48': False, '49': False, '50': False, '51': False, '52': False, '53': False, '54': False, '55': True, '56': False, '57': False, '58': False, '59': True, '60': False, '61': False, '62': False, '63': False, '64': False, '65': False, '66': False, '67': False, '68': False, '18': False}\n"
     ]
    }
   ],
   "source": [
    "answers = dict()\n",
    "for i in range(len(querys)):\n",
    "    determine_abbrevation = f\"\"\" \n",
    "    You are an scientific expert especially in the domain of Information Retrieval. Your task is to detect whether\n",
    "    a given query, which is given as a text below delimited by triple quotes, contains an abbrevation then answer with yes or not then answer with no.\n",
    "    For example given a query 'What is crx' you should answer yes, since cxr is the abbrevation for the medical term\n",
    "    'chest X-Ray'. However if the given query is 'What is Information Retrieval' you should answer no, since there is no\n",
    "    abbrevation in the query.\n",
    "\n",
    "    query: '''{querys['query'][i]}'''\n",
    "    \"\"\"\n",
    "    answer = ask_gpt(prompt=determine_abbrevation) #check answer more carefully perhaps model will return not only {yes,no}\n",
    "    #print(answer)\n",
    "    qid = str(querys['qid'][i])\n",
    "    if \"yes\" in answer.lower().strip():\n",
    "        answers[qid] = True\n",
    "    else:\n",
    "        answers[qid] = False\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand query which contains abbrevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm acceleration with nvidia cuda\n",
      "The abbreviation in the query is 'cuda'. CUDA stands for 'Compute Unified Device Architecture'. Therefore, the new query after concatenating the written out abbreviation with the original query is 'Compute Unified Device Architecture algorithm acceleration with nvidia cuda'.\n",
      "bm25\n",
      "The abbreviation in the query is 'bm25', which stands for 'Best Matching 25'. Therefore, the new query after concatenating the written out abbreviation with the original query is 'Best Matching 25 bm25'.\n",
      "what is ahp\n",
      "The abbreviation in the query is 'ahp', which stands for 'Analytic Hierarchy Process'. Therefore, the new query after concatenating the written out abbreviation with the original query is 'Analytic Hierarchy Process what is ahp'.\n"
     ]
    }
   ],
   "source": [
    "#could be more efficient if in answers text is saved only for qid where abbrevation=yes\n",
    "for key in answers.keys():\n",
    "    if bool(answers[key]):\n",
    "        #find query\n",
    "        for i in range(len(querys)):\n",
    "            if querys['qid'][i] == key:\n",
    "                query= querys['query'][i]\n",
    "                print(query)\n",
    "        #ask gpt to expand query\n",
    "        expand = f\"\"\" \n",
    "        You are an scientific expert especially in the domain of Information Retrieval. Your are given a query, which is below\n",
    "        delimited by triple quotes, which contains an abbrevation. Your task is to identify the abbrevation and write it, then\n",
    "        concat the written out abbrevation with the original query and return this new query as string only.\n",
    "        For example given a query 'What is crx' you should detect that the abbrevation is crx, since cxr is the abbrevation for the medical term\n",
    "        'chest X-Ray', then your should concat the abbrevation 'chest X-Ray' with the originial query resulting in a new query 'chest X-Ray What is crx' which\n",
    "        you should return. Another example, given the query 'Algorithms of nlp' you should detect that the abbrevation is nlp, since nlp is the abbrevation\n",
    "        for the term 'natural language processing', then you should concat the abbrevation 'natural language processing' with the original query 'Algorithms of nlp' \n",
    "        resulting in a new query 'natural language processing Algorithms of nlp' which you should return.\n",
    "\n",
    "        query: '''{query}'''\n",
    "        \"\"\"\n",
    "        new_query = ask_gpt(prompt=expand)\n",
    "        print(new_query)\n",
    "        #overwrite old query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
