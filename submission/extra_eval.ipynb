{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>machine learning language identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>social media detect self harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>stemming for arabic languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                                     query\n",
       "0   1  retrieval system improving effectiveness\n",
       "1   2  machine learning language identification\n",
       "2   3             social media detect self harm\n",
       "3   4             stemming for arabic languages"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "pt_dataset.get_topics('query').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('text', 'title', 'query', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>recall_1000</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.374041</td>\n",
       "      <td>0.579877</td>\n",
       "      <td>0.825376</td>\n",
       "      <td>0.262311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ngrams</td>\n",
       "      <td>0.352402</td>\n",
       "      <td>0.567611</td>\n",
       "      <td>0.717923</td>\n",
       "      <td>0.226362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  ndcg_cut.10  recip_rank  recall_1000       map\n",
       "0    BM25     0.374041    0.579877     0.825376  0.262311\n",
       "1  Ngrams     0.352402    0.567611     0.717923  0.226362"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This assumes we have execited the ../baseline-retrieval-system/baseline-retrieval-system.ipynb notebook before.\n",
    "bm25 = pt.io.read_results('../runs/runbm25.txt')\n",
    "ngrams = pt.io.read_results('../runs/runngram.txt')\n",
    "pt.Experiment(\n",
    "    [bm25, ngrams],\n",
    "    pt_dataset.get_topics(),\n",
    "    pt_dataset.get_qrels(),\n",
    "    [\"ndcg_cut.10\", \"recip_rank\", \"recall_1000\", \"map\"],\n",
    "    names=[\"BM25\", \"Ngrams\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('text', 'title', 'query', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n",
      "   name       map  recip_rank  recall_1000  ndcg_cut.10  map +  map -  \\\n",
      "0  BM25  0.262311    0.579877     0.825376     0.374041    NaN    NaN   \n",
      "1  Full  0.180295    0.514831     0.707547     0.289385   21.0   46.0   \n",
      "\n",
      "   map p-value  recip_rank +  recip_rank -  recip_rank p-value  recall_1000 +  \\\n",
      "0          NaN           NaN           NaN                 NaN            NaN   \n",
      "1     0.000124          20.0          27.0            0.249336            7.0   \n",
      "\n",
      "   recall_1000 -  recall_1000 p-value  ndcg_cut.10 +  ndcg_cut.10 -  \\\n",
      "0            NaN                  NaN            NaN            NaN   \n",
      "1           42.0             0.000005           25.0           36.0   \n",
      "\n",
      "   ndcg_cut.10 p-value  \n",
      "0                  NaN  \n",
      "1             0.008987  \n"
     ]
    }
   ],
   "source": [
    "# This assumes we have execited the ../baseline-retrieval-system/baseline-retrieval-system.ipynb notebook before.\n",
    "bm25 = pt.io.read_results('./runs/bm25.txt')\n",
    "#ngrams = pt.io.read_results('../runs/runngram.txt')\n",
    "full = pt.io.read_results('./runs/fullrun/run.txt')\n",
    "res_dict = pt.Experiment(\n",
    "    [bm25, full],\n",
    "    pt_dataset.get_topics(),\n",
    "    pt_dataset.get_qrels(),\n",
    "    [\"ndcg_cut.10\", \"recip_rank\", \"recall_1000\", \"map\"],\n",
    "    names=[\"BM25\", \"Full\"],\n",
    "    baseline=0,\n",
    "    #perquery = True,\n",
    "    save_dir = \"./\",\n",
    "    save_mode=\"overwrite\",\n",
    "    dataframe = True\n",
    ")\n",
    "print(res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET A LIST OF QUERIES WHERE WE HAVE BETTER MAP THAN BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   name       map  recip_rank  recall_1000  ndcg_cut.10  map +  map -  \\\n",
      "0  BM25  0.262311    0.579877     0.825376     0.374041    NaN    NaN   \n",
      "1  Full  0.180295    0.514831     0.707547     0.289385   21.0   46.0   \n",
      "\n",
      "   map p-value  recip_rank +  recip_rank -  recip_rank p-value  recall_1000 +  \\\n",
      "0          NaN           NaN           NaN                 NaN            NaN   \n",
      "1     0.000124          20.0          27.0            0.249336            7.0   \n",
      "\n",
      "   recall_1000 -  recall_1000 p-value  ndcg_cut.10 +  ndcg_cut.10 -  \\\n",
      "0            NaN                  NaN            NaN            NaN   \n",
      "1           42.0             0.000005           25.0           36.0   \n",
      "\n",
      "   ndcg_cut.10 p-value  \n",
      "0                  NaN  \n",
      "1             0.008987  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'measure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'measure'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Filter criteria\u001b[39;00m\n\u001b[1;32m      5\u001b[0m filter_criteria \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeasure\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      7\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBM25\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Apply the filter\u001b[39;00m\n\u001b[1;32m     11\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[filter_criteria]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'measure'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(res_dict)\n",
    "print(df)\n",
    "# Filter criteria\n",
    "filter_criteria = (\n",
    "    (df['measure'] == 'map') &\n",
    "    (df['name'].isin(['Full', 'BM25']))\n",
    ")\n",
    "\n",
    "# Apply the filter\n",
    "filtered_df = df[filter_criteria]\n",
    "\n",
    "# Group by 'qid' and filter groups that have both 'NGRAMS' and 'BM25' entries\n",
    "groups = filtered_df.groupby('qid')\n",
    "valid_pairs = []\n",
    "valid_qids = []\n",
    "for qid, group in groups:\n",
    "    if len(group) == 2 and set(group['name']) == {'Full', 'BM25'}:\n",
    "        ngrams_row = group[group['name'] == 'Full'].iloc[0]\n",
    "        bm25_row = group[group['name'] == 'BM25'].iloc[0]\n",
    "        \n",
    "        if ngrams_row['value'] > bm25_row['value']:\n",
    "            valid_pairs.append((ngrams_row, bm25_row))\n",
    "            valid_qids.append(qid)\n",
    "# Print the valid pairs\n",
    "for ngrams_row, bm25_row in valid_pairs:\n",
    "    print(f\"Pair found for qid {ngrams_row['qid']}:\")\n",
    "    print(f\"Full: {ngrams_row}\")\n",
    "    print(f\"BM25: {bm25_row}\")\n",
    "    print(valid_qids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('text', 'title', 'query', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n",
      "   qid                                               text  \\\n",
      "1    2           machine learning language identification   \n",
      "2    3                      social media detect self-harm   \n",
      "5    6              Comparison different retrieval models   \n",
      "8    9                          Pseudo-relevance feedback   \n",
      "9   10  How to represent natural conversations in word...   \n",
      "12  13                             at least three authors   \n",
      "18  20           Crawling websites using machine learning   \n",
      "20  22                      Search engine caching effects   \n",
      "22  24                       Limitations machine learning   \n",
      "23  25                          medicine related research   \n",
      "24  26                        Natural Language Processing   \n",
      "27  29  information retrieval on different language so...   \n",
      "29  31   risks of information retrieval in social media ?   \n",
      "37  39      informational retrieval using neural networks   \n",
      "38  40                                 Query log analysis   \n",
      "47  49                             exhaustivity of index    \n",
      "50  52                                   reverse indexing   \n",
      "54  56   What makes Natural Language Processing natural?    \n",
      "63  65                  information in different language   \n",
      "64  66                           Abbreviations in queries   \n",
      "65  67                           lemmatization algorithms   \n",
      "\n",
      "                                                title  \\\n",
      "1            machine learning language identification   \n",
      "2                       social media detect self-harm   \n",
      "5               Comparison different retrieval models   \n",
      "8                           Pseudo-relevance feedback   \n",
      "9   How to represent natural conversations in word...   \n",
      "12                             at least three authors   \n",
      "18           Crawling websites using machine learning   \n",
      "20                      Search engine caching effects   \n",
      "22                       Limitations machine learning   \n",
      "23                          medicine related research   \n",
      "24                        Natural Language Processing   \n",
      "27  information retrieval on different language so...   \n",
      "29   risks of information retrieval in social media ?   \n",
      "37      informational retrieval using neural networks   \n",
      "38                                 Query log analysis   \n",
      "47                             exhaustivity of index    \n",
      "50                                   reverse indexing   \n",
      "54   What makes Natural Language Processing natural?    \n",
      "63                  information in different language   \n",
      "64                           Abbreviations in queries   \n",
      "65                           lemmatization algorithms   \n",
      "\n",
      "                                                query  \\\n",
      "1            machine learning language identification   \n",
      "2                       social media detect self harm   \n",
      "5               comparison different retrieval models   \n",
      "8                           pseudo relevance feedback   \n",
      "9   how to represent natural conversations in word...   \n",
      "12                             at least three authors   \n",
      "18           crawling websites using machine learning   \n",
      "20                      search engine caching effects   \n",
      "22                       limitations machine learning   \n",
      "23                          medicine related research   \n",
      "24                        natural language processing   \n",
      "27  information retrieval on different language so...   \n",
      "29     risks of information retrieval in social media   \n",
      "37      informational retrieval using neural networks   \n",
      "38                                 query log analysis   \n",
      "47                              exhaustivity of index   \n",
      "50                                   reverse indexing   \n",
      "54     what makes natural language processing natural   \n",
      "63                  information in different language   \n",
      "64                           abbreviations in queries   \n",
      "65                           lemmatization algorithms   \n",
      "\n",
      "                                          description  \\\n",
      "1   What papers are about machine learning for lan...   \n",
      "2   Which papers focus on how to recognize signs o...   \n",
      "5   Which different retrieval models exist and wha...   \n",
      "8   How does pseudo-relevance feedback improve a q...   \n",
      "9   How is it possible to filter and classify info...   \n",
      "12         Which entries have at least three authors?   \n",
      "18  Papers that describe how to use AI to crawl th...   \n",
      "20  Papers that describe the effects and/or effici...   \n",
      "22  Which papers describe the limitations of machi...   \n",
      "23           Papers that did research on medical data   \n",
      "24  Find papers that include the term natural lang...   \n",
      "27  What articles identify the impact of sources i...   \n",
      "29   What are the risks associated with using info...   \n",
      "37    Which papers include research on using neura...   \n",
      "38  Which papers include research on query log ana...   \n",
      "47  Documents that include explanations for what e...   \n",
      "50            What sources explain reverse indexing?    \n",
      "54  What is Natural Language Processing and why is...   \n",
      "63  Which papers cover Cross-language information ...   \n",
      "64  Which papers cover the handling of abbreviatio...   \n",
      "65       Which papers cover lemmatization algorithms?   \n",
      "\n",
      "                                            narrative  \n",
      "1   Relevant papers include research on methods of...  \n",
      "2   Relevant papers include research on early dete...  \n",
      "5   Relevant documents include the description and...  \n",
      "8   Documents that specifically showcase how this ...  \n",
      "9   Relevant documents include information about e...  \n",
      "12  Relevant entries have at least three authors. ...  \n",
      "18  Papers in this topic describe methods and algo...  \n",
      "20  Papers in this topic will describe the design ...  \n",
      "22  Relevant papers describe the limitations of ma...  \n",
      "23  Find papers that did their research on medical...  \n",
      "24                                                     \n",
      "27  Relevant documents must concern more than one ...  \n",
      "29  Relevant documents must discuss the risks of u...  \n",
      "37   Relevant papers discuss using neural networks...  \n",
      "38  Papers that involves the analysis of logs of u...  \n",
      "47  Relevant documents include the words index and...  \n",
      "50   Relevant sources that focus on reverse indexi...  \n",
      "54  Natural Language Processing is a model to proc...  \n",
      "63  Relevant papers cover concepts, that fall unde...  \n",
      "64  Relevant papers cover concepts, that deal with...  \n",
      "65  Relevant IR documents cover the topic of lemma...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#print(pt_dataset.get_topics())\n",
    "#valid_qids_normal = ['10', '18', '20', '28', '29', '3', '31', '33', '39', '4', '49', '51', '56', '62', '65', '68']\n",
    "df = pd.DataFrame(pt_dataset.get_topics())\n",
    "#print(df)\n",
    "\n",
    "filtered_df = df[df['qid'].isin(valid_qids)]\n",
    "# Printing the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET ALL QUERIES WHERE WE HAVE BETTER RECALL THAN BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name qid      measure     value\n",
      "0    BM25   1          map  0.404455\n",
      "1    BM25   1   recip_rank  1.000000\n",
      "2    BM25   1  recall_1000  0.966667\n",
      "3    BM25   1  ndcg_cut.10  0.835780\n",
      "36   BM25  10          map  0.001188\n",
      "..    ...  ..          ...       ...\n",
      "303  Full   8  ndcg_cut.10  0.000000\n",
      "304  Full   9          map  0.160744\n",
      "305  Full   9   recip_rank  0.166667\n",
      "306  Full   9  recall_1000  1.000000\n",
      "307  Full   9  ndcg_cut.10  0.154481\n",
      "\n",
      "[544 rows x 4 columns]\n",
      "Pair found for qid 16:\n",
      "Full: name              Full\n",
      "qid                 16\n",
      "measure    recall_1000\n",
      "value         0.842105\n",
      "Name: 334, dtype: object\n",
      "BM25: name              BM25\n",
      "qid                 16\n",
      "measure    recall_1000\n",
      "value         0.684211\n",
      "Name: 62, dtype: object\n",
      "['16', '24', '29', '5', '52', '56', '65']\n",
      "Pair found for qid 24:\n",
      "Full: name              Full\n",
      "qid                 24\n",
      "measure    recall_1000\n",
      "value              1.0\n",
      "Name: 366, dtype: object\n",
      "BM25: name              BM25\n",
      "qid                 24\n",
      "measure    recall_1000\n",
      "value         0.833333\n",
      "Name: 94, dtype: object\n",
      "['16', '24', '29', '5', '52', '56', '65']\n",
      "Pair found for qid 29:\n",
      "Full: name              Full\n",
      "qid                 29\n",
      "measure    recall_1000\n",
      "value          0.71875\n",
      "Name: 386, dtype: object\n",
      "BM25: name              BM25\n",
      "qid                 29\n",
      "measure    recall_1000\n",
      "value          0.65625\n",
      "Name: 114, dtype: object\n",
      "['16', '24', '29', '5', '52', '56', '65']\n",
      "Pair found for qid 5:\n",
      "Full: name              Full\n",
      "qid                  5\n",
      "measure    recall_1000\n",
      "value              1.0\n",
      "Name: 290, dtype: object\n",
      "BM25: name              BM25\n",
      "qid                  5\n",
      "measure    recall_1000\n",
      "value         0.818182\n",
      "Name: 18, dtype: object\n",
      "['16', '24', '29', '5', '52', '56', '65']\n",
      "Pair found for qid 52:\n",
      "Full: name              Full\n",
      "qid                 52\n",
      "measure    recall_1000\n",
      "value              0.8\n",
      "Name: 478, dtype: object\n",
      "BM25: name              BM25\n",
      "qid                 52\n",
      "measure    recall_1000\n",
      "value              0.7\n",
      "Name: 206, dtype: object\n",
      "['16', '24', '29', '5', '52', '56', '65']\n",
      "Pair found for qid 56:\n",
      "Full: name              Full\n",
      "qid                 56\n",
      "measure    recall_1000\n",
      "value              0.5\n",
      "Name: 494, dtype: object\n",
      "BM25: name              BM25\n",
      "qid                 56\n",
      "measure    recall_1000\n",
      "value           0.4375\n",
      "Name: 222, dtype: object\n",
      "['16', '24', '29', '5', '52', '56', '65']\n",
      "Pair found for qid 65:\n",
      "Full: name              Full\n",
      "qid                 65\n",
      "measure    recall_1000\n",
      "value              0.5\n",
      "Name: 530, dtype: object\n",
      "BM25: name              BM25\n",
      "qid                 65\n",
      "measure    recall_1000\n",
      "value              0.1\n",
      "Name: 258, dtype: object\n",
      "['16', '24', '29', '5', '52', '56', '65']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(res_dict)\n",
    "print(df)\n",
    "# Filter criteria\n",
    "filter_criteria = (\n",
    "    (df['measure'] == 'recall_1000') &\n",
    "    (df['name'].isin(['Full', 'BM25']))\n",
    ")\n",
    "\n",
    "# Apply the filter\n",
    "filtered_df = df[filter_criteria]\n",
    "\n",
    "# Group by 'qid' and filter groups that have both 'NGRAMS' and 'BM25' entries\n",
    "groups = filtered_df.groupby('qid')\n",
    "valid_pairs = []\n",
    "valid_qids = []\n",
    "for qid, group in groups:\n",
    "    if len(group) == 2 and set(group['name']) == {'Full', 'BM25'}:\n",
    "        ngrams_row = group[group['name'] == 'Full'].iloc[0]\n",
    "        bm25_row = group[group['name'] == 'BM25'].iloc[0]\n",
    "        \n",
    "        if ngrams_row['value'] > bm25_row['value']:\n",
    "            valid_pairs.append((ngrams_row, bm25_row))\n",
    "            valid_qids.append(qid)\n",
    "# Print the valid pairs\n",
    "for ngrams_row, bm25_row in valid_pairs:\n",
    "    print(f\"Pair found for qid {ngrams_row['qid']}:\")\n",
    "    print(f\"Full: {ngrams_row}\")\n",
    "    print(f\"BM25: {bm25_row}\")\n",
    "    print(valid_qids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
