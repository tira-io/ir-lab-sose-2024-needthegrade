{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab SoSe 2024: Baseline Retrieval System\n",
    "\n",
    "This jupyter notebook serves as baseline retrieval system that you can try to improve upon.\n",
    "We will use the a corpus of scientific papers (title + abstracts) from the fields of information retrieval and natural language processing (the [IR Anthology](https://ir.webis.de/anthology/) and the [ACL Anthology](https://aclanthology.org/)). This serves Jupyter notebook only serves as retrieval system, i.e., it gets a set of information needs (topics) and a corpus as input and produces a run file as output. Please do evaluations in a new dedicated notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "\n",
    "We will use [tira](https://www.tira.io/), an information retrieval shared task platform, for loading the (pre-built) retrieval index and [ir_dataset](https://ir-datasets.com/) to subsequently build a retrieval system with [PyTerrier](https://github.com/terrier-org/pyterrier), an open-source search engine.\n",
    "\n",
    "Building your own index can be already one way that you can try to improve upon this baseline (if you want to focus on creating good document representations). Other ways could include reformulating queries or tuning parameters or building better retrieval pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTerrier initialized with custom Terrier JAR!\n",
      "Number of documents: 3\n",
      "Number of terms: 14\n",
      "Number of postings: 17\n",
      "Number of fields: 1\n",
      "Number of tokens: 20\n",
      "Field names: [text]\n",
      "Positions:   false\n",
      "\n",
      "cat\n",
      "1\n",
      "doesnt\n",
      "1\n",
      "hous\n",
      "1\n",
      "implement\n",
      "1\n",
      "larg\n",
      "1\n",
      "million\n",
      "1\n",
      "mous\n",
      "1\n",
      "pipelin\n",
      "1\n",
      "retriev\n",
      "3\n",
      "scale\n",
      "1\n",
      "system\n",
      "5\n",
      "time\n",
      "1\n",
      "try\n",
      "1\n",
      "work\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "\n",
    "# Initialize PyTerrier with the custom JAR file\n",
    "pt.init(\n",
    "    #version='5.9',  # specify the version corresponding to your custom JAR\n",
    "    #home_dir=None,  # set to None if JAR is in ~/.pyterrier\n",
    "    #packages=['org.terrier:terrier-project:5.9'],\n",
    "    #no_download=True\n",
    ")\n",
    "\n",
    "from pyterrier.index import IterDictIndexer\n",
    "# Your PyTerrier code goes here\n",
    "print(\"PyTerrier initialized with custom Terrier JAR!\")\n",
    "\n",
    "\n",
    "#index = tira.pt.index('ir-lab-sose-2024-needthegrade/baseline-retrieval-system/index_ngram2', test_dataset)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize PyTerrier\n",
    "\n",
    "\n",
    "# Create an instance of the custom indexer\n",
    "index_path = \"./my_custom_index\"\n",
    "custom_indexer = IterDictIndexer(index_path) #, tokeniser='UTFTokenizer'\n",
    "\n",
    "# Example documents to index\n",
    "docs = [\n",
    "    {\"docno\": \"0\", \"text\": \"information retrieval systems for about a million times i try to do the system for the retrieval pipeline, why doesnt it work\"},\n",
    "    {\"docno\": \"1\", \"text\": \"house cat mouse system\"},\n",
    "    {\"docno\" : \"2\", \"text\" : \"systems for implementing large scale retrieval systems\"}\n",
    "]\n",
    "\n",
    "# Index the documents\n",
    "index_ref = custom_indexer.index(docs)\n",
    "\n",
    "# Now you can use the index_ref as usual\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "print(index.getCollectionStatistics())\n",
    "for term, le in index.getLexicon():\n",
    "    print(term) \n",
    "    print(le.getFrequency())\n",
    "\n",
    "# Access the MetaIndex and Lexicon\n",
    "meta = index.getMetaIndex()\n",
    "lexicon = index.getLexicon()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "from pyterrier.index import IterDictIndexer\n",
    "import pandas as pd #extra import\n",
    "from sklearn.feature_extraction.text import CountVectorizer #extra import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset and the Index\n",
    "\n",
    "The type of the index object that we load is `<class 'jnius.reflect.org.terrier.structures.Index'>`, in fact a [Java class](http://terrier.org/docs/v3.6/javadoc/org/terrier/structures/Index.html) wrapped into Python. However, you do not need to worry about this: at this point, we will simply use the provided Index object to run procedures defined in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom tokenizer method.\n",
    "This method takes a String as an argument and returns a List of all tokens, including ngrams between 1 and 3 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Iterator for our dataset. This is an Iterator where every element is a dict which contains a text and a docno.\n",
    "See the example print below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Retrieval Pipeline\n",
    "\n",
    "We will define a BM25 retrieval pipeline as baseline. For details, see:\n",
    "\n",
    "- [https://pyterrier.readthedocs.io](https://pyterrier.readthedocs.io)\n",
    "- [https://github.com/terrier-org/ecir2021tutorial](https://github.com/terrier-org/ecir2021tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we do the retrieval...\n",
      "Done. Here are the first 10 entries of the run\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.768400</td>\n",
       "      <td>retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.888397</td>\n",
       "      <td>retrieval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid docno  rank     score      query\n",
       "0   0      2     2     0 -0.768400  retrieval\n",
       "1   0      0     0     1 -0.888397  retrieval"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Now we do the retrieval...')\n",
    "#run = bm25(test_dataset.get_topics('text'))\n",
    "run = bm25([{\"qid\": \"0\", \"query\" : \"retrieval\"}])\n",
    "print('Done. Here are the first 10 entries of the run')\n",
    "run.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes for docid 0: {'docno': '0', 'text': ''}\n",
      "Attributes for docid 1: {'docno': '1', 'text': ''}\n",
      "Attributes for docid 2: {'docno': '2', 'text': ''}\n",
      "Attributes for docid 3: {'docno': '3', 'text': ''}\n"
     ]
    }
   ],
   "source": [
    "#index = pt.IndexFactory.of(index_ref)\n",
    "meta = index.getMetaIndex()\n",
    "\n",
    "# List of metadata keys\n",
    "meta_keys = ['docno', 'text']  # Adjust this list based on your meta fields\n",
    "\n",
    "# Function to print document attributes\n",
    "def print_doc_attributes(docid):\n",
    "    attributes = {key: meta.getItem(key, docid) for key in meta_keys}\n",
    "    print(f\"Attributes for docid {docid}: {attributes}\")\n",
    "\n",
    "# Example: Print attributes for the first 5 documents\n",
    "for docid in range(4):\n",
    "    print_doc_attributes(docid)\n",
    "\n",
    "# Function to print document attributes by docno\n",
    "def print_doc_attributes_by_docno(docno):\n",
    "    try:\n",
    "        docid = meta.getDocument(\"docno\", docno)\n",
    "        print_doc_attributes(docid)\n",
    "    except KeyError:\n",
    "        print(f\"Document with docno {docno} not found.\")\n",
    "\n",
    "# List of specific docnos to retrieve\n",
    "#docnos = ['W05-0704']\n",
    "\n",
    "# Retrieve and print attributes for each specified docno\n",
    "#for docno in docnos:\n",
    " #   print_doc_attributes_by_docno(docno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Persist the run file for subsequent evaluations\n",
    "\n",
    "The output of a prototypical retrieval system is a run file. This run file can later (optimally in a different notebook) be statistically evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "persist_and_normalize_run(run, system_name='bm25-baseline', default_output='../runs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
