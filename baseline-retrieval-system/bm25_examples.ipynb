{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, we have a short look at the first three topics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>machine learning language identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>social media detect self harm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                                     query\n",
       "0   1  retrieval system improving effectiveness\n",
       "1   2  machine learning language identification\n",
       "2   3             social media detect self harm"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('First, we have a short look at the first three topics:')\n",
    "\n",
    "pt_dataset.get_topics('text').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we do the retrieval...\n",
      "Done. Here are the first 10 entries of the run\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>94858</td>\n",
       "      <td>2004.cikm_conference-2004.47</td>\n",
       "      <td>0</td>\n",
       "      <td>15.681777</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>125137</td>\n",
       "      <td>1989.ipm_journal-ir0volumeA25A4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>15.047380</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>125817</td>\n",
       "      <td>2005.ipm_journal-ir0volumeA41A5.11</td>\n",
       "      <td>2</td>\n",
       "      <td>14.144223</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5868</td>\n",
       "      <td>W05-0704</td>\n",
       "      <td>3</td>\n",
       "      <td>14.025748</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>84876</td>\n",
       "      <td>2016.ntcir_conference-2016.90</td>\n",
       "      <td>4</td>\n",
       "      <td>13.947994</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>82472</td>\n",
       "      <td>1998.sigirconf_conference-98.15</td>\n",
       "      <td>5</td>\n",
       "      <td>13.901647</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>94415</td>\n",
       "      <td>2008.cikm_conference-2008.183</td>\n",
       "      <td>6</td>\n",
       "      <td>13.808208</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>17496</td>\n",
       "      <td>O01-2005</td>\n",
       "      <td>7</td>\n",
       "      <td>13.749449</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>82490</td>\n",
       "      <td>1998.sigirconf_conference-98.33</td>\n",
       "      <td>8</td>\n",
       "      <td>13.735541</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>124801</td>\n",
       "      <td>2006.ipm_journal-ir0volumeA42A3.2</td>\n",
       "      <td>9</td>\n",
       "      <td>13.569263</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>111300</td>\n",
       "      <td>2005.trec_conference-2005.26</td>\n",
       "      <td>10</td>\n",
       "      <td>13.557375</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>126826</td>\n",
       "      <td>2007.tois_journal-ir0volumeA26A1.4</td>\n",
       "      <td>11</td>\n",
       "      <td>13.545496</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>116566</td>\n",
       "      <td>1988.jasis_journal-ir0volumeA39A2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>13.398527</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>74513</td>\n",
       "      <td>2001.clef_workshop-2001w.24</td>\n",
       "      <td>13</td>\n",
       "      <td>13.356503</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>125153</td>\n",
       "      <td>2008.ipm_journal-ir0volumeA44A3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>13.315896</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>37861</td>\n",
       "      <td>C10-2130</td>\n",
       "      <td>15</td>\n",
       "      <td>13.313734</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>87595</td>\n",
       "      <td>2017.fire_conference-2017w.27</td>\n",
       "      <td>16</td>\n",
       "      <td>13.245531</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>73906</td>\n",
       "      <td>2007.ntcir_workshop-2007.65</td>\n",
       "      <td>17</td>\n",
       "      <td>13.245185</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>81840</td>\n",
       "      <td>2006.sigirconf_conference-2006.103</td>\n",
       "      <td>18</td>\n",
       "      <td>13.237362</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>74730</td>\n",
       "      <td>2008.clef_workshop-2008.10</td>\n",
       "      <td>19</td>\n",
       "      <td>13.188310</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid   docid                                docno  rank      score  \\\n",
       "0    1   94858         2004.cikm_conference-2004.47     0  15.681777   \n",
       "1    1  125137    1989.ipm_journal-ir0volumeA25A4.2     1  15.047380   \n",
       "2    1  125817   2005.ipm_journal-ir0volumeA41A5.11     2  14.144223   \n",
       "3    1    5868                             W05-0704     3  14.025748   \n",
       "4    1   84876        2016.ntcir_conference-2016.90     4  13.947994   \n",
       "5    1   82472      1998.sigirconf_conference-98.15     5  13.901647   \n",
       "6    1   94415        2008.cikm_conference-2008.183     6  13.808208   \n",
       "7    1   17496                             O01-2005     7  13.749449   \n",
       "8    1   82490      1998.sigirconf_conference-98.33     8  13.735541   \n",
       "9    1  124801    2006.ipm_journal-ir0volumeA42A3.2     9  13.569263   \n",
       "10   1  111300         2005.trec_conference-2005.26    10  13.557375   \n",
       "11   1  126826   2007.tois_journal-ir0volumeA26A1.4    11  13.545496   \n",
       "12   1  116566  1988.jasis_journal-ir0volumeA39A2.0    12  13.398527   \n",
       "13   1   74513          2001.clef_workshop-2001w.24    13  13.356503   \n",
       "14   1  125153    2008.ipm_journal-ir0volumeA44A3.9    14  13.315896   \n",
       "15   1   37861                             C10-2130    15  13.313734   \n",
       "16   1   87595        2017.fire_conference-2017w.27    16  13.245531   \n",
       "17   1   73906          2007.ntcir_workshop-2007.65    17  13.245185   \n",
       "18   1   81840   2006.sigirconf_conference-2006.103    18  13.237362   \n",
       "19   1   74730           2008.clef_workshop-2008.10    19  13.188310   \n",
       "\n",
       "                                       query  \n",
       "0   retrieval system improving effectiveness  \n",
       "1   retrieval system improving effectiveness  \n",
       "2   retrieval system improving effectiveness  \n",
       "3   retrieval system improving effectiveness  \n",
       "4   retrieval system improving effectiveness  \n",
       "5   retrieval system improving effectiveness  \n",
       "6   retrieval system improving effectiveness  \n",
       "7   retrieval system improving effectiveness  \n",
       "8   retrieval system improving effectiveness  \n",
       "9   retrieval system improving effectiveness  \n",
       "10  retrieval system improving effectiveness  \n",
       "11  retrieval system improving effectiveness  \n",
       "12  retrieval system improving effectiveness  \n",
       "13  retrieval system improving effectiveness  \n",
       "14  retrieval system improving effectiveness  \n",
       "15  retrieval system improving effectiveness  \n",
       "16  retrieval system improving effectiveness  \n",
       "17  retrieval system improving effectiveness  \n",
       "18  retrieval system improving effectiveness  \n",
       "19  retrieval system improving effectiveness  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Now we do the retrieval...')\n",
    "run = bm25(pt_dataset.get_topics('text'))\n",
    "\n",
    "print('Done. Here are the first 10 entries of the run')\n",
    "run.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 retrieval system improving effectiveness\n",
      "1 machine learning language identification\n",
      "2 social media detect self harm\n",
      "3 stemming for arabic languages\n",
      "4 audio based animal recognition\n",
      "5 comparison different retrieval models\n",
      "6 cache architecture\n",
      "7 document scoping formula\n",
      "8 pseudo relevance feedback\n",
      "9 how to represent natural conversations in word nets\n",
      "10 algorithm acceleration with nvidia cuda\n",
      "11 mention of algorithm\n",
      "12 at least three authors\n",
      "13 german domain\n",
      "14 mention of open source\n",
      "15 inclusion of text mining\n",
      "16 the ethics of artificial intelligence\n",
      "17 machine learning for more relevant results\n",
      "18 crawling websites using machine learning\n",
      "19 recommenders influence on users\n",
      "20 search engine caching effects\n",
      "21 consumer product reviews\n",
      "22 limitations machine learning\n",
      "23 medicine related research\n",
      "24 natural language processing\n",
      "25 graph based ranking\n",
      "26 medical studies that use information retrieval\n",
      "27 information retrieval on different language sources\n",
      "28 papers that compare multiple information retrieval methods\n",
      "29 risks of information retrieval in social media\n",
      "30 actual experiments that strengthen theoretical knowledge\n",
      "31 fake news detection\n",
      "32 multimedia retrieval\n",
      "33 processing natural language for information retrieval\n",
      "34 recommendation systems\n",
      "35 personalised search in e commerce\n",
      "36 sentiment analysis\n",
      "37 informational retrieval using neural networks\n",
      "38 query log analysis\n",
      "39 entity recognition\n",
      "40 relevance assessments\n",
      "41 deep neural networks\n",
      "42 information retrieval\n",
      "43 analysis for android apps\n",
      "44 the university of amsterdam\n",
      "45 neural ranking for ecommerce product search\n",
      "46 web pages evolution\n",
      "47 exhaustivity of index\n",
      "48 query optimization\n",
      "49 cosine similarity vector\n",
      "50 reverse indexing\n",
      "51 index compression techniques\n",
      "52 search engine optimization with query logs\n",
      "53 bm25\n",
      "54 what makes natural language processing natural\n",
      "55 principle of a information retrieval indexing\n",
      "56 architecture of web search engine\n",
      "57 what is ahp\n",
      "58 what is information retrieval\n",
      "59 efficient retrieval algorithms\n",
      "60 how to avoid spam results\n",
      "61 information retrieval with algorithms\n",
      "62 misspellings in queries\n",
      "63 information in different language\n",
      "64 abbreviations in queries\n",
      "65 lemmatization algorithms\n",
      "66 filter ad rich documents\n",
      "67 advancements in information retrieval\n"
     ]
    }
   ],
   "source": [
    "for i,query in enumerate(pt_dataset.get_topics('query')['query']):\n",
    "    print(i,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     qid  docid             docno  rank      score  \\\n",
      "9000  10   2925          E83-1021     0  20.916117   \n",
      "9001  10  23308          W03-1403     1  19.225459   \n",
      "9002  10  32141  2020.figlang-1.8     2  19.015074   \n",
      "9003  10  56494          W19-7510     3  18.394361   \n",
      "9004  10  39091          W12-4804     4  17.761019   \n",
      "9005  10  49784          C80-1002     5  17.743728   \n",
      "9006  10  56442      2019.gwc-1.7     6  17.493578   \n",
      "9007  10  66935          E99-1009     7  17.345538   \n",
      "9008  10  65142          J77-4003     8  17.336473   \n",
      "9009  10  27993          P18-1014     9  17.163196   \n",
      "\n",
      "                                                  query  \n",
      "9000  how to represent natural conversations in word...  \n",
      "9001  how to represent natural conversations in word...  \n",
      "9002  how to represent natural conversations in word...  \n",
      "9003  how to represent natural conversations in word...  \n",
      "9004  how to represent natural conversations in word...  \n",
      "9005  how to represent natural conversations in word...  \n",
      "9006  how to represent natural conversations in word...  \n",
      "9007  how to represent natural conversations in word...  \n",
      "9008  how to represent natural conversations in word...  \n",
      "9009  how to represent natural conversations in word...  \n"
     ]
    }
   ],
   "source": [
    "slice = run[9000:9010]\n",
    "print(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      qid   docid                                        docno  rank  \\\n",
      "42000  44   84131            2003.sigirconf_conference-2003.73     0   \n",
      "42001  44  101568                 2015.ictir_conference-2015.2     1   \n",
      "42002  44  126596           2011.tois_journal-ir0volumeA29A2.0     2   \n",
      "42003  44   19891                                     C94-2169     3   \n",
      "42004  44  122130  2012.sigirjournals_journal-ir0volumeA46A1.9     4   \n",
      "42005  44  124838            2006.ipm_journal-ir0volumeA42A1.2     5   \n",
      "42006  44   83081            2005.sigirconf_conference-2005.64     6   \n",
      "42007  44   82931           2013.sigirconf_conference-2013.125     7   \n",
      "42008  44   93970                  2014.cikm_conference-2014.9     8   \n",
      "42009  44   80905           2008.sigirconf_conference-2008.170     9   \n",
      "\n",
      "          score                  query  \n",
      "42000  6.025493  information retrieval  \n",
      "42001  5.912126  information retrieval  \n",
      "42002  5.868038  information retrieval  \n",
      "42003  5.845946  information retrieval  \n",
      "42004  5.812470  information retrieval  \n",
      "42005  5.797285  information retrieval  \n",
      "42006  5.793518  information retrieval  \n",
      "42007  5.787117  information retrieval  \n",
      "42008  5.783849  information retrieval  \n",
      "42009  5.774567  information retrieval  \n"
     ]
    }
   ],
   "source": [
    "slice2 = run[42000:42010]\n",
    "print(slice2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      qid   docid                                        docno  rank  \\\n",
      "56283  60   84131            2003.sigirconf_conference-2003.73     0   \n",
      "56284  60  101568                 2015.ictir_conference-2015.2     1   \n",
      "56285  60  126596           2011.tois_journal-ir0volumeA29A2.0     2   \n",
      "56286  60   19891                                     C94-2169     3   \n",
      "56287  60  122130  2012.sigirjournals_journal-ir0volumeA46A1.9     4   \n",
      "56288  60  124838            2006.ipm_journal-ir0volumeA42A1.2     5   \n",
      "56289  60   83081            2005.sigirconf_conference-2005.64     6   \n",
      "56290  60   82931           2013.sigirconf_conference-2013.125     7   \n",
      "56291  60   93970                  2014.cikm_conference-2014.9     8   \n",
      "56292  60   80905           2008.sigirconf_conference-2008.170     9   \n",
      "\n",
      "          score                          query  \n",
      "56283  6.025493  what is information retrieval  \n",
      "56284  5.912126  what is information retrieval  \n",
      "56285  5.868038  what is information retrieval  \n",
      "56286  5.845946  what is information retrieval  \n",
      "56287  5.812470  what is information retrieval  \n",
      "56288  5.797285  what is information retrieval  \n",
      "56289  5.793518  what is information retrieval  \n",
      "56290  5.787117  what is information retrieval  \n",
      "56291  5.783849  what is information retrieval  \n",
      "56292  5.774567  what is information retrieval  \n"
     ]
    }
   ],
   "source": [
    "slice3 = run[56283:56293]\n",
    "print(slice3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E83-1021', 'W03-1403', '2020.figlang-1.8', 'W19-7510', 'W12-4804', 'C80-1002', '2019.gwc-1.7', 'E99-1009', 'J77-4003', 'P18-1014']\n"
     ]
    }
   ],
   "source": [
    "docnos = list(slice['docno'])\n",
    "print(docnos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [00:02<00:00, 53931.97it/s]\n"
     ]
    }
   ],
   "source": [
    "text = list()\n",
    "for doc in pt_dataset.get_corpus_iter():\n",
    "    for docno in docnos:\n",
    "        if doc['docno'] == docno:\n",
    "            text.append(docno + '\\n' + doc['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 E83-1021\n",
      "An Approach to Natural Language in the {SI-N}ets Paradigm\n",
      "\n",
      "\n",
      " Thls article deals with the interpretation of conceptual operations underlying the communicative use of natural language (NL) within the Structured Inheritance Network (Sl-Nets) paradigm. The operations are reduced to functions of a fo~al language, thus changing the level of abstraction of the operations to be performed on SI-Nets. In this sense, operations on SI-Nets are not merely isomorphic to single epistemologleal objects, but can be viewed as a simulation of processes on a different level, that pertaining to the conceptual system of NL. For this purpose, we have designed a version of KL-ONE which represents\n",
      "\n",
      "1 W03-1403\n",
      "Is There a Way to Represent Metaphors in {W}ord{N}ets? Insights from the {H}amburg Metaphor Database\n",
      "\n",
      "\n",
      " This paper addresses the question whether metaphors can be represented in Word-Nets. For this purpose, domain-centered data is collected from the Hamburg Metaphor Database, an online source created for the study of possible metaphor representations in WordNets. Based on the results of the analyses of French and German corpus data and EuroWordNet, the implementation problem is discussed. It can be shown that a much more complete representation of synsets and relations between synsets in the source domain as well as a clearer indication of the level of figurativity for individual synsets are needed before global conceptual metaphors can be dealt with in Word-Nets.\n",
      "\n",
      "2 P18-1014\n",
      "Extractive Summarization with {SWAP}-{NET}: Sentences and Words from Alternating Pointer Networks\n",
      "\n",
      "\n",
      " We present a new neural sequence-tosequence model for extractive summarization called SWAP-NET (Sentences and Words from Alternating Pointer Networks). Extractive summaries comprising a salient subset of input sentences, often also contain important key words. Guided by this principle, we design SWAP-NET that models the interaction of key words and salient sentences using a new twolevel pointer network based architecture. SWAP-NET identifies both salient sentences and key words in an input document, and then combines them to form the extractive summary. Experiments on large scale benchmark corpora demonstrate the efficacy of SWAP-NET that outperforms state-of-the-art extractive summarizers.\n",
      "\n",
      "3 2020.figlang-1.8\n",
      "{C}-Net: Contextual Network for Sarcasm Detection\n",
      "\n",
      "\n",
      " Automatic Sarcasm Detection in conversations is a difficult and tricky task. Classifying an utterance as sarcastic or not in isolation can be futile since most of the time the sarcastic nature of a sentence heavily relies on its context. This paper presents our proposed model, C-Net, which takes contextual information of a sentence in a sequential manner to classify it as sarcastic or non-sarcastic. Our model showcases competitive performance in the Sarcasm Detection shared task organised on CodaLab and achieved 75.0% F1-score on the Twitter dataset and 66.3% F1-score on Reddit dataset.\n",
      "\n",
      "4 W12-4804\n",
      "Using Collocations and K-means Clustering to Improve the N-pos Model for {J}apanese {IME}\n",
      "\n",
      "\n",
      " Kana-Kanji conversion is known as one of the representative applications of Natural Language Processing (NLP) for the Japanese language. The N-pos model, presenting the probability of a Kanji candidate sequence by the product of bi-gram Part-of-Speech (POS) probabilities and POS-to-word emission probabilities, has been successfully applied in a number of well-known Japanese Input Method Editor (IME) systems. However, since N-pos model is an approximation of n-gram word-based language model, important word-to-word collocation information are lost during this compression and lead to a drop of the conversion accuracies. In order to overcome this problem, we propose ways to improve current N-pos model. One way is to append the highfrequency collocations and the other way is to sub-categorize the huge POS sets to make them more representative. Experiments on large-scale data verified our proposals.\n",
      "\n",
      "5 C80-1002\n",
      "Automatic Processing of Written {F}rench Language\n",
      "\n",
      "\n",
      " An automatic processor of written French language is described. This processor uses syntactic and semantic informations about words in order to construct a semantic net representing the meaning of the sentences. The structure of the network and the principles of the parser are explained. An application to the processing of the medical records is then discussed.\n",
      "\n",
      "6 2019.gwc-1.7\n",
      "The Extended {A}rabic {W}ord{N}et: a Case Study and an Evaluation using a Word Sense Disambiguation System\n",
      "\n",
      "\n",
      " Arabic WordNet (AWN) represents one of the best-known lexical resources for the Arabic language. However, it contains various issues that affect its use in different Natural Language Processing (NLP) applications. Due to resources deficiency, the update of Arabic WordNet requires much effort. There have only been only two updates it was first published in 2006. The most significant of those being in 2013, which represented a significant development in the usability and coverage of Arabic WordNet. This paper provides a study case on the updates of the Arabic Word-Net and the development of its contents. More precisely, we present the new content in terms of relations that have been added to the extended version of Arabic WordNet. We also validate and evaluate its contents at different levels. We use its different versions in a Word Sense Disambiguation system. Finally, we compare the results and evaluate them. Results show that newly added semantic relations can improve the performance of a Word Sense Disambiguation system.\n",
      "\n",
      "7 W19-7510\n",
      "Vaijayant{\\=\\i}ko{\\'s}a Knowledge-Net\n",
      "\n",
      "\n",
      " A kośa (lexicon) is a literary work that provides a comprehensive understanding of words by arranging them along with their synonyms and other words that are semantically related. Its format has been designed to include not just ontological classification, but to give a holistic idea of a concept represented by the word. This allows a thorough understanding of the words, and also the knowledge they embody. Vaijayantīkośa is a popular Sanskrit lexicon that contains words from spoken language as well those used in Vedic literature. To facilitate dissemination of this knowledge, a web-based tool, Vaijayantīkośa Knowledge Net, is created for easy access and analysis of the words in the kośa. The objective of the tool is to provide information to researchers from different fields of study to explore the knowledge contained in the kośa with the help of synsets and ontological structure.\n",
      "\n",
      "8 J77-4003\n",
      "Spatial Reference and Semantic Nets\n",
      "\n",
      "\n",
      " This paper presents an analysis in a semantic net formalism of the semantic structure of English sentences containing references to spatial-location. Spatial reference, hereafter -SR, provides either static location or motional information John is at home, Fred ran across the street to the store. .The task for the semantic analysis of sentences with SR's is to,make clear what is being positioned. THis has been difficult to do. Previous proposals have left unanalyzed many phenomena including important motional references. This paperv* main conclusion is that a much improved analysis can be obtained by representing the SR's as positioning abstract events and states of affairs. The analysis in semantic nets has the location of an event or state of affairs represented as a node which is linked to the node showing the event or state by arcs: indicating its staus as the spatial attribute. A few SR's are shown as naming these locational entities, which we call place ,object. These SR' s involve examples with \"where\", \"here\", and \"there\" However, most SRts are represented as relating place objects to the position of objects in the manner of prepositional phrases. This primacy ok prepositions is argued for in the paper. Motional references are allowed for by functions represented in the nets which If we hear example 2.2 t h e n more than John i s known t o be i n the basement. His c a r d s a r e , for. example.\n",
      "\n",
      "9 E99-1009\n",
      "Geometry of Lexico-Syntactic Interaction\n",
      "\n",
      "\n",
      " Interaction of lexical and derivational semantics---for example substitution and lambda conversion---is typically a part of the on-line interpretation process. Proof-nets are to categorial grammar what phrase markers are to phrase structure grammar: unique graphical structures underlying equivalence classes of sequential syntactic derivations; but the role of proof-nets is deeper since they integrate also semantics. In this paper we show how interaction of lexical and derivational semantics at the lexico-syntactic interface can be precomputed as a process of off-line lexical compilation comprising Cut elimination in partial proof-nets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(text):\n",
    "    print(i,item)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
